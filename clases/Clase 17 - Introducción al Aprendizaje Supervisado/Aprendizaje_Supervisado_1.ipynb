{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGh-Be9IF3EM"
      },
      "source": [
        "# Clase 17: Introducci√≥n al Aprendizaje Supervisado\n",
        "\n",
        "\n",
        "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
        "\n",
        "**Profesor: Mat√≠as Rojas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KocntejMF3EO"
      },
      "source": [
        "## Objetivos de la clase: \n",
        "   \n",
        "- Introducir al aprendizaje supervisado mediante el uso de ejemplos aplicados.\n",
        "- Entender el framework utilizado para resolver la tarea de clasificaci√≥n y reforzar los contenidos asociados a la ingenier√≠a de caracter√≠sticas.\n",
        "- Estudiar las m√©tricas de evaluaci√≥n m√°s comunes para la tarea seleccionada.\n",
        "- Entender la idea de Holdout y K-Fold para evaluar modelos.\n",
        "- Experimentar con los primeros modelos de clasificaci√≥n del curso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fODAnNtoF3EP"
      },
      "source": [
        "## Panorama General Hasta el Momento\n",
        "\n",
        "<div align='center'>\n",
        "<img src='https://i.ibb.co/DRvgXs6/etapas.png'/>\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<div align='center'>\n",
        "<img src=\"https://i.ibb.co/BT3Dt2L/machine-learning.png\" alt=\"Panorama General ML: Clasificaci√≥n supervisada, No supervisada y Aprendizaje Reforzado binario\" width=700/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1jMgmQ7F3EP"
      },
      "source": [
        "El aprendizaje autom√°tico es el estudio de algoritmos que autom√°ticamente mejoran su rendimiento a trav√©s de la experiencia. Estos algoritmos construyen modelos basados en datos de muestra con la intenci√≥n de realizar predicciones sin ser expl√≠citamente programados para hacerlo.\n",
        "\n",
        "## Aprendizaje Supervisado\n",
        "\n",
        "El aprendizaje supervisado se basa en trabajar con datasets cuyas observaciones son **caracter√≠sticas** que describen a alg√∫n objeto. Estas observaciones adem√°s cuentan con una **etiqueta/valor real**, la cu√°l corresponde a una clase o valor que se le asigna a cada observaci√≥n.\n",
        "\n",
        "Cuando el valor a predecir es un(a): \n",
        "\n",
        "- Categor√≠a/Etiqueta, el problema que se resuelve se denomina **Clasificaci√≥n**.\n",
        "- Valor real, el problema que se resuelve se denomina **Regresi√≥n**.\n",
        "\n",
        "\n",
        "En otras palabras, las etiquetas pertenecen a un n√∫mero finito de clases. Por ejemplo, en caso que estemos describiendo a una persona, el vector asociado a cada observaci√≥n puede contener los siguentes **features/caracter√≠sticas**:\n",
        "\n",
        "- su altura en cm, \n",
        "- edad, \n",
        "- peso en kg, \n",
        "- residencia, \n",
        "- etc...\n",
        "\n",
        "Mientras que la **etiqueta** puede ser si la persona *quiere o no contratar un servicio de internet*, es decir un valor boolenao, $\\{ True, False\\}$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7SEeIU1F3EP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ejemplo de un dataset con una etiqueta con un conjunto de datos discreto (clasificaci√≥n).\n",
        "pd.DataFrame(\n",
        "    [[177, 43, 72, \"Maip√∫\", True], [160, 16, 60, \"Pudahuel\", False]],\n",
        "    columns=[\"Altura\", \"Edad\", \"Peso\", \"Residencia\", \"Posible cliente?\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facFLZjbF3EQ"
      },
      "source": [
        "Como tambi√©n lo que est√° dispuesto a gastar en el plan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WurUHverF3ER"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de un dataset con una etiqueta con un conjunto de datos continuo (regresi√≥n).\n",
        "pd.DataFrame(\n",
        "    [[177, 43, 72, \"Maip√∫\", 55000], [160, 16, 60, \"Pudahuel\", 0]],\n",
        "    columns=[\"Altura\", \"Edad\", \"Peso\", \"Residencia\", \"Cu√°nto est√° dispuesto a pagar?\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35vUe3ZBF3ER"
      },
      "source": [
        "Dado un conjunto de datos etiquetados, el objetivo del aprendizaje supervisado es crear algoritmos/modelos que permitan **asignar de forma autom√°tica categor√≠as o valores a observaciones nuevas**. \n",
        "\n",
        "En t√©rminos pr√°cticos, dada una nueva observaci√≥n representada por su vector de caracter√≠sticas, el modelo generado debe ser capaz de asignar una etiqueta a dicha observaci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbkJEaVwF3ER"
      },
      "source": [
        "### Framework General de Aprendizaje Supervisado Cl√°sico\n",
        "\n",
        "La siguiente lista muestra las etapas que deber√≠a cumplir un algoritmo de aprendizaje supervisado cl√°sico (i.e., no red neuronal)\n",
        "\n",
        "1. **Feature Engineering y Preprocesamiento**: Recolectar y preparar los datos.\n",
        "2. **Entrenar** un algoritmo de clasificaci√≥n/regresi√≥n usando los datos.\n",
        "3. **Evaluar** qu√© tan bien el clasificador puede clasificar nuevos ejemplos.\n",
        "4. **Optimizar los modelos** modificando sus hiperpar√°metros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoYxBzzXF3ER"
      },
      "source": [
        "### Feature Engineering\n",
        "\n",
        "Feature Engineering/Ingenier√≠a de Caracter√≠sticas es la etapa en que se transforman los \"datos raw/crudos\" de entrada en un dataset, de manera que se tengan datos robustos para ser usados por el clasificador/regresor que desean entrenar.\n",
        "\n",
        "\n",
        "Este proceso incluye: \n",
        "\n",
        "- **Creaci√≥n de nuevas Features** a partir de operaciones usando los datos disponibles.\n",
        "- **Transformaciones** como las vistas en la clase de preprocesamiento (escalamiento, normalizaci√≥n, one hot encoding para variables categ√≥ricas etc...).\n",
        "- **Reducci√≥n de Caracter√≠sticas** en la que se combinan/reducen caracter√≠sticas redundantes (usando por ejemplo, PCA).\n",
        "- **Selecci√≥n de Caracter√≠sticas** en la que a partir de diversos criterios se seleccionan las caracter√≠sticas que m√°s aportan al modelo.\n",
        "\n",
        "El proceso de generar y preprocesar las features requiere mucha creatividad y al mismo conocimiento del dominio del problema.\n",
        "\n",
        "La creaci√≥n de nuevas caracter√≠sticas puede incluir: \n",
        "\n",
        "- **Generaci√≥n de features a partir de la combinaci√≥n de otras**: Sumar, restar, multiplicar y contar distintas features puede agregar m√°s informaci√≥n que ellas por si mismas. Esto tambi√©n incluye el preprocesar features independientemente con funciones no linales como $\\log$, $\\exp$, etc...\n",
        "- **Discretizaci√≥n de una variable num√©rica a trav√©s de Binning**: Transformar una variable num√©rica a una variable categ√≥rica seg√∫n rangos usando bins o percentiles. Recordar el uso de los m√©todos `cut` y `qcut`. Ver tambi√©n `Binarizer` y `KBinsDiscretizer` en `sklearn.preprocessing`.\n",
        "- **Clusters** generados a partir de las features (no incluir las labels! es la informaci√≥n que quieren predecir)\n",
        "- **Bag-of-words para texto**. T√©cnica similar a One Hot encoding en donde cada palabra es una columna y se cuenta la cantidad de apariciones de cada palabra en una oraci√≥n.\n",
        "- **Seno/Coseno** para codificar variables c√≠clicas, como las horas, d√≠as, meses o a√±os. Por ejemplo, para los d√≠as de la semana en donde $p \\in \\{1,2,3,4,5,6,7\\}$, se pueden generar dos features usando \n",
        "$$\n",
        "p_{sin} = \\sin{\\frac{2 \\times \\pi \\times p}{\\max{p}}} \n",
        "$$\n",
        "y\n",
        "$$\n",
        "p_{cos} = \\cos{\\frac{2 \\times \\pi \\times p}{\\max{p}}} \n",
        "$$\n",
        "- **Datos Temporales**: La idea aqu√≠ es transformar toda la secuencia temporal a un vector que la describa. Para esto, se pueden calcular descriptores como media, moda, tiempo entre valles, picos, diferencias entre valles y picos en un determinado tiempo, etc...  .Una librer√≠a √∫til para esto es tsfel: https://tsfel.readthedocs.io/en/latest/\n",
        "- **Transformaciones polinomiales a variables num√©ricas**: Esto se basa en que en dimensiones m√°s altas/no lineales los datos pueden mostrar patrones que no se presentan en los datos originales y que pueden ser aprendidas por el algoritmo. Ver la transformaci√≥n `PolynomialFeatures` de `sklearn.preprocessing`.\n",
        "\n",
        "Una feature buena cumple que: \n",
        "\n",
        "- **Tiene un alto poder predictivo**\n",
        "- **Computabilidad r√°pida** \n",
        "- **No correlaci√≥n con otras features**\n",
        "\n",
        "Este proceso debe ser determinista ya que al momento de predecir datos nuevos, las transformaciones y features calculadas sobre estos deben ser las mismas que las utilizadas en el proceso de entrenamiento. Para solucionar esto, es muy recomendable usar los `Pipelines`.\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI3z4hNqF3ES"
      },
      "source": [
        "\n",
        "\n",
        "El modelo construido debe **generalizar**, es decir, debe ser capaz de realizar predicciones correctas en nuevas observaciones. Para esto es √∫til pensar que el modelo generado est√° separando los datos por clases a trav√©s de un *decision boundary*. Mientras m√°s holgado sea este *decision boundary*, mejor podr√° generalizar el modelo.\n",
        "\n",
        "<div align='center'>\n",
        "<img src='https://i.ibb.co/3mcx35c/overfitting.png' witdh=400/>\n",
        "\n",
        "</div>\n",
        "\n",
        "<div align='center'>\n",
        "<a href='https://www.researchgate.net/figure/Example-of-overfitting-in-classification-a-Decision-boundary-that-best-fits-training_fig1_349186066'>Ejemplo de *Overfitting* en researchgate</a>\n",
        "</div>\n",
        "    \n",
        "<br/>\n",
        " \n",
        "### C√≥mo determinar que algorimo utilizar \n",
        " \n",
        "Muchas veces se piensa que lo m√°s importante es la **capacidad predictiva** del modelo.\n",
        "Sin embargo, tambi√©n hay otros factores muy relevantes que determinar√°n que algoritmo predictivo utilizar: \n",
        "\n",
        "**Eficiencia**: \n",
        "  - ¬øQu√© tanto se est√° demorando mi modelo en entrenar? \n",
        "  - ¬øY en predecir? \n",
        "  - ¬øEs eficiente en memoria? \n",
        "  - ¬øDebe almacenar el dataset de entrenamiento para funcionar?\n",
        "  - ¬øEs posible usarlo en tiempo real para alg√∫n tipo de soluci√≥n online?\n",
        "  \n",
        "**N√∫mero de Features y Ejemplos Requeridos**: \n",
        "  - ¬øCu√°ntos datos o features son requeridos para entrenar el modelo?\n",
        "  - ¬øEs compatible con la cantidad que dispongo?\n",
        "  - ¬øEl tipo de features (i.e., categor√≠cas, num√©ricas, combinaci√≥n de ambas, etc...) es compatible con el algoritmo?\n",
        "  \n",
        "**Explicabilidad**: \n",
        "  - ¬øPuedo explicar por qu√© el modelo est√° clasificando/regresionando de la manera que lo hace? \n",
        "  \n",
        "***Fairness***: \n",
        "  - ¬øMi modelo es injusto con respecto a alg√∫n grupo social?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7u9VS5RF3ES"
      },
      "source": [
        "\n",
        "### ¬øC√≥mo saber si un modelo es bueno o no?\n",
        "\n",
        "Resumimos la capacidad predictiva de un modelo mediante **m√©tricas de desempe√±o** (performance metrics).\n",
        "\n",
        "Las m√©tricas se calculan contrastando los valores predichos versus los valores reales de la variable objetivo (con datos no usados durante entrenamiento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMqpMT3sF3ES"
      },
      "source": [
        "##  Matriz de Confusi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qFmeiCJF3ES"
      },
      "source": [
        "<div align='center'>\n",
        "    <img src=\"https://i.ibb.co/5sMqPDR/matriz-conf.png\" alt=\"Ejemplo de una matriz de confusi√≥n para un problema de clasificaci√≥n binario\" width=450/>\n",
        "</div>\n",
        "\n",
        "<center>Ejemplo de una matriz de confusi√≥n para un problema de clasificaci√≥n binario.</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S3BzvHMF3ES"
      },
      "source": [
        "---\n",
        "\n",
        "> Ejemplo: Alergia a cierto medicamento en donde la clase `+` indica alergia.\n",
        "\n",
        "\n",
        "Nuestro dataset tiene 10.000 observaciones distribuidos de la siguiente forma:\n",
        "\n",
        "- Clase `+`: 100 observaciones.\n",
        "- Clase `-`: 9900 observaciones.\n",
        "\n",
        "\n",
        "Luego, creamos un modelo que clasific√≥ nuestro dataset y graficamos sus resultados a trav√©s de la siguiente matriz de confusi√≥n:\n",
        "\n",
        "\n",
        "|                    | **Predicha (`+`)**  | **Predicha (`-`)** |\n",
        "|--------------------|---------------------|--------------------|\n",
        "| **Real (`+`)**     | 10                  | 90                 |\n",
        "| **Real (`-`)**     | 100                 | 9800               |\n",
        "\n",
        "---\n",
        "\n",
        "> **Pregunta**: ¬øCuales m√©tricas de desempe√±o conocen para evaluar este caso?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJoJcE4kF3ES"
      },
      "source": [
        "### M√©tricas de desempe√±o\n",
        "\n",
        "M√©tricas basadas en contar datos correcta e incorrectamente clasificados:\n",
        "\n",
        "- **Accuracy (Exactitud)**: $$\\text{accuracy} = \\frac{\\text{n√∫mero de predicciones correctas}}{\\text{n√∫mero de predicciones totales}}$$\n",
        "\n",
        "- **Error rate (Tasa de error)**: $$\\text{error rate} = \\frac{\\text{n√∫mero de predicciones incorrectas}}{\\text{n√∫mero de predicciones totales}}$$\n",
        "\n",
        "\n",
        "\n",
        "- En nuestro ejemplo anterior: \n",
        "\n",
        "$$\\text{accuracy} = \\frac{9810}{10000} = 0.981$$\n",
        "\n",
        "$$\\text{error rate} = \\frac{190}{10000} = 0.019$$\n",
        "\n",
        "\n",
        "> **Pregunta ‚ùì:** ¬øCu√°l es el problema de `Accuracy` en nuestro ejemplo?\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg6KuykhF3ET"
      },
      "source": [
        "#### M√©tricas Basadas en la Matriz de Confusi√≥n\n",
        "\n",
        "Una posible soluci√≥n a este problema son las m√©tricas basadas en la matriz de confusi√≥n:\n",
        "\n",
        "<div align='center'>\n",
        "    <img src=\"https://i.ibb.co/5sMqPDR/matriz-conf.png\" alt=\"Ejemplo de una matriz de confusi√≥n para un problema de clasificaci√≥n binario\" width=450/>\n",
        "</div>\n",
        "\n",
        "- **Precision**:  Fracci√≥n de ejemplos correctamente predichos como `+` con respecto a todos los predichos `+`.\n",
        "\n",
        "$$P = \\frac{\\text{Clasificados correctamente como positivo}}{\\text{Todos los predichos como positivos}} =\\frac{TP}{(TP + FP)}$$\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "- **Recall**: Fracci√≥n de ejemplos `+` que son correctamente clasificados: \n",
        "\n",
        "$$R = \\frac{\\text{Clasificados correctamente como positivo}}{\\text{Todos los que deber√≠a haber clasificado como positivos}}  = \\frac{TP}{(TP+FN)}$$\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "- **F1 measure**: Combina precisi√≥n y recall usando una media arm√≥nica (i.e., media que castiga si ambos valores son muy diferentes).\n",
        "\n",
        "$$F = \\frac{2PR}{(P+R)}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlLc3w9qF3ET"
      },
      "source": [
        "\n",
        "|                    | **Predicha (`+`)**  | **Predicha (`-`)** |\n",
        "|--------------------|---------------------|--------------------|\n",
        "| **Real (`+`)**     | 10                  | 90                 |\n",
        "| **Real (`-`)**     | 100                 | 9800               |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_G9a6Y3F3ET"
      },
      "source": [
        "En nuestro ejemplo anterior:\n",
        "\n",
        "\n",
        "$$P = \\frac{10}{110} = 0.\\bar{09}$$\n",
        "\n",
        "$$R = \\frac{10}{100} = 0.1$$\n",
        "\n",
        "$$F = \\frac{2 \\cdot 0.1 \\cdot 0.\\bar{1}}{(0.1 + 0.\\bar{1})} \\approx 0.095$$ \n",
        "\n",
        "Ahora claramente se nota el problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LbJOOg4zF3ET"
      },
      "outputs": [],
      "source": [
        "p = 10 / 110\n",
        "r = 10 / 100\n",
        "\n",
        "f = 2 * p * r / (p + r)\n",
        "f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1oA0tVSF3ET"
      },
      "source": [
        "#### Matriz de confusi√≥n multiclase\n",
        "\n",
        "Cuando tenemos $k$ clases, la matriz de confusi√≥n es una matriz de $k \\times k$.\n",
        "\n",
        "<div align='center'>\n",
        "<img src=\"https://i.ibb.co/Z2Strv9/matriz-conf-multiclase.png\" alt=\"Ejemplo de una matriz de confusi√≥n para un problema de clasificaci√≥n binario\" style=\"width: 500px;\"/>\n",
        "</div>\n",
        "\n",
        "¬øC√≥mo calculamos las m√©tricas?\n",
        "\n",
        "\n",
        "#### M√©tricas de Desempe√±o Generalizadas: \n",
        "\n",
        "\n",
        "- Precision: Fracci√≥n de ejemplos asignados a la clase `i` que son realmente de la clase `i`.\n",
        "\n",
        "$$\\text{precision} = \\frac{c_{ii}}{\\sum_{j}c_{ji}}$$\n",
        "\n",
        "\n",
        "- Recall: Fracci√≥n de ejemplos de la clase `i` correctamente clasificados: \n",
        "\n",
        "$$\\text{recall} = \\frac{c_{ii}}{\\sum_{j}c_{ij}}$$\n",
        "\n",
        "- Accuracy: Fracci√≥n de ejemplos correctamente clasificados:\n",
        "\n",
        "$$\\text{accuracy} = \\frac{\\sum_{i}c_{ii}}{\\sum_{j}\\sum_{i}c_{ij}}$$\n",
        "\n",
        "#### Estrategia de Agregaci√≥n\n",
        "\n",
        "- **Macroaveraging**\n",
        "    - Computar m√©trica para cada clase y luego promediar. \n",
        "    - Sobrerepresentan clases minoritarias al tratar a todas por igual.\n",
        "\n",
        "- **Weighted**\n",
        "    - Computar m√©trica para cada clase y luego hace un promedio ponderado por el n√∫mero de ejemplos de esa clase.\n",
        "    - Al ser ponderado por el n√∫mero de casos, da m√°s prioridad a las clases frecuentes.\n",
        "\n",
        "\n",
        "`Scikit` provee un acceso r√°pido a todas estas m√©tricas a trav√©s de su funci√≥n `sklearn.metrics.classification_report`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVhjw7jOF3ET"
      },
      "source": [
        "### Underfitting y Overfitting\n",
        "\n",
        "Errores de entrenamiento o **Underfitting**. \n",
        "- Malos resultados sobre los datos de entrenamiento\n",
        "- El clasificador no tiene capacidad de aprender el patr√≥n.\n",
        "\n",
        "Errores de generalizaci√≥n o **Overfitting**. \n",
        "- Malos resultados sobre datos nuevos \n",
        "- El modelo se hace demasiado espec√≠fico a los datos de entrenamiento. \n",
        "\n",
        "\n",
        "<div align='center'>\n",
        "<img src='https://i.ibb.co/Sc7SBs2/tipos-fit.png' width=800/>\n",
        "</div>\n",
        "\n",
        "<div align='center'>\n",
        "    Fuente: The Hundred-Page Machine Learning Book.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-07T19:45:34.649513Z",
          "start_time": "2020-09-07T19:45:34.617566Z"
        },
        "id": "OUgg-zZtF3ET"
      },
      "source": [
        "## Nuestro problema de hoy: Ping√ºinos  üêß\n",
        "\n",
        "\n",
        "Origen del dataset:\n",
        "\n",
        "**Palmer Archipelago (Antarctica) penguin data**: \n",
        "\n",
        "*Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.*\n",
        "\n",
        "https://github.com/allisonhorst/palmerpenguins\n",
        "\n",
        "![Pinguinos](https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/lter_penguins.png)\n",
        "\n",
        "\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvjH5nNKF3EU"
      },
      "source": [
        "### Atributos\n",
        " \n",
        "- `culmen_length_mm`: Largo del culmen (v√©rtice o borde superior de la mand√≠bula)  (mm).\n",
        "- `culmen_depth_mm`: Alto del culmen (v√©rtice o borde superior de la mand√≠bula) (mm).\n",
        "- `flipper_length_mm`: Longitud de las aletas (mm).\n",
        "- `body_mass_g`: Masa corporal (g).\n",
        "- `island`: Isla de origen (Dream, Torgersen, or Biscoe) en el archipi√©lago de Palmer (Antarctica).\n",
        "- `sex`: Sexo del pinguino.\n",
        "\n",
        "![Detalle Variables](https://allisonhorst.github.io/palmerpenguins/reference/figures/culmen_depth.png)\n",
        "    \n",
        "<center>Cr√©ditos a Allison Horst por sus excelentes ilustraciones https://github.com/allisonhorst </center>    \n",
        "    \n",
        "    \n",
        "### Variable a predecir\n",
        "\n",
        "- `species`: Especie del pinguino (Chinstrap, Ad√©lie, or Gentoo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-07T18:13:05.372393Z",
          "start_time": "2020-09-07T18:13:05.369428Z"
        },
        "id": "FB7wKYUEF3EU"
      },
      "source": [
        "## Exploraci√≥n y Preprocesamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:11.776288Z",
          "start_time": "2020-09-11T17:43:00.371984Z"
        },
        "scrolled": true,
        "id": "8CWaSbP8F3EU"
      },
      "outputs": [],
      "source": [
        "# Instalar graphviz para visualizar el √°rbol generado\n",
        "# Deben instalar antes graphviz: https://www.graphviz.org/download/\n",
        "\n",
        "import sys\n",
        "\n",
        "!pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:11.786261Z",
          "start_time": "2020-09-11T17:43:11.778282Z"
        },
        "id": "_HD7R_ETF3EU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:11.818175Z",
          "start_time": "2020-09-11T17:43:11.788255Z"
        },
        "id": "yM46LZwnF3EU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"penguins.csv\").dropna().reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:11.906937Z",
          "start_time": "2020-09-11T17:43:11.822164Z"
        },
        "id": "hlq2y714F3EU"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "    df, dimensions=df.iloc[:, 2:].columns, color=\"species\", height=1000\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3YHwJsNF3EU"
      },
      "outputs": [],
      "source": [
        "px.parallel_categories(df, dimensions=[\"island\", \"species\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uv0A22bF3EU"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWRKeyFVF3EU"
      },
      "source": [
        "---\n",
        "\n",
        "## Holdout\n",
        "\n",
        "Consiste en particionar nuestro dataset en conjuntos de:\n",
        "\n",
        "- **Training**: conjunto que se utiliza para **entrenar** el modelo.\n",
        "- **Testing**: datos que se usa para **evaluar** qu√© tan bien predice el modelo (a trav√©s de las m√©tricas de evaluaci√≥n). \n",
        "\n",
        "\n",
        "Comunmente se dividen en proporci√≥n $2/3$ y $1/3$ del dataset respectivamente. Sin embargo, todo depende de la cantidad de datos que se posean: si se tiene millones de ejemplos, quizas puede dividirse en 95% train, 5% test sin problemas. \n",
        "\n",
        "\n",
        "La evaluaci√≥n puede variar mucho seg√∫n las particiones escogidas: \n",
        "\n",
        "- Training peque√±o -> modelo sesgado, \n",
        "- Testing peque√±o -> evaluaci√≥n poco confiable.\n",
        "\n",
        "\n",
        "Esta t√©nica se puede **Random Subsampling** para seleccionar aleatoriamente las observaciones de cada uno de estos conjuntos.\n",
        "\n",
        "Para ejecutar todo esto usaremos `train_test_split`. Veamos algunos de sus par√°metros:\n",
        "\n",
        "- `test_size = 0.33` - indica el tama√±o del test de evaluaci√≥n.\n",
        "- `shuffle = True` - indica que ejecutaremos Random Subsampling.\n",
        "- `stratify = labels` - intenta manetener la distribuci√≥n de clases original en ambos conjuntos.\n",
        "\n",
        "\n",
        "### Validation set:\n",
        "\n",
        "Cuando se desea realizar una b√∫squeda de los mejores algoritmos y sus hiperpar√°metros, el dataset puede ser dividido en 3:\n",
        "\n",
        "\n",
        "- **Training**: Se utiliza para entrenar los modelos.\n",
        "- **Validation**: Se utiliza para seleccionar el mejor modelo al ir variando sus hiperpar√°metros.\n",
        "- **Testing**: Se utiliza para evaluar el modelo previo a ser entregado o puesto en producci√≥n. Esta evaluaci√≥n solo se hace sobre el modelo final.\n",
        "\n",
        "\n",
        "En este caso la divisi√≥n puede ser $70\\%, 15\\%, 15\\%$ respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:12.091444Z",
          "start_time": "2020-09-11T17:43:12.083466Z"
        },
        "id": "JnfNCKAfF3EU"
      },
      "outputs": [],
      "source": [
        "# Holdout\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = df.drop(columns=[\"species\"])\n",
        "labels = df.loc[:, \"species\"]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.33, shuffle=True, stratify=labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_ByrBfhF3EU"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:12.118372Z",
          "start_time": "2020-09-11T17:43:12.094436Z"
        },
        "scrolled": true,
        "id": "-R_QwYUqF3EU"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fWlakDPF3EV"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxIJPDBUF3EV"
      },
      "outputs": [],
      "source": [
        "# distribuci√≥n original\n",
        "labels.value_counts() / labels.count() * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_BMNvG80F3EV"
      },
      "outputs": [],
      "source": [
        "# conjunto de entrenamiento\n",
        "y_train.value_counts() / y_train.count() * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "UZlG2KJjF3EV"
      },
      "outputs": [],
      "source": [
        "# conjunto de pruebas\n",
        "y_test.value_counts() / y_test.count() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtT4CfEJF3EV"
      },
      "source": [
        "\n",
        "\n",
        "### Otra Opci√≥n: `cross-validation`\n",
        "\n",
        "Se particiona el dataset en k conjuntos disjuntos o folds:\n",
        "\n",
        "---\n",
        "    Para cada partici√≥n i:\n",
        "        - Juntar todas las k-1 particiones restantes y entrenar el modelo sobre esos datos.\n",
        "        - Evaluar el modelo en la partici√≥n i.\n",
        "        \n",
        "    El error total = suma de errores de todos los modelos  \n",
        "\n",
        "---\n",
        "\n",
        "<img src='https://i.ibb.co/Sc7SBs2/tipos-fit.png' width=400>\n",
        "\n",
        "\n",
        "Veremos m√°s de esto en las pr√≥ximas clases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-tQDffNF3EV"
      },
      "source": [
        "### Preprocesamiento y Data Leakage\n",
        "\n",
        "\n",
        "Data Leakage o fuga de datos se refiere al uso de datos de prueba dentro del entrenamiento de un modelo predictivo (lo que ovbiamente es incorrecto).\n",
        "\n",
        "Es muy importante que el **preprocesamiento y feature engineering lo hagan siempre sobre los datos de entrenamiento y no sobre todo el dataset**. De lo contrario, estar√≠an ocupando datos destinados a evaluar para entrenar el modelo (o el preprocesamiento) lo que puede inducir a resultados muy buenos cuando en verdad no deber√≠an serlos.\n",
        "\n",
        "\n",
        "Mas informaci√≥n en [data-leakage de scikit-learn](https://scikit-learn.org/stable/common_pitfalls.html#data-leakage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvuy-OtkF3EV"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21qV7sq0F3EV"
      },
      "outputs": [],
      "source": [
        "ct = ColumnTransformer(\n",
        "    [\n",
        "        (\n",
        "            \"Scaler\",\n",
        "            RobustScaler(),\n",
        "            [\n",
        "                \"culmen_length_mm\",\n",
        "                \"culmen_depth_mm\",\n",
        "                \"flipper_length_mm\",\n",
        "                \"body_mass_g\",\n",
        "            ],\n",
        "        ),\n",
        "        (\"OneHot\", OneHotEncoder(sparse=False), [\"island\", \"sex\"]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2Rg3C41F3EV"
      },
      "outputs": [],
      "source": [
        "X_train_preprocessed = pd.DataFrame(\n",
        "    ct.fit_transform(X_train),\n",
        "    columns=np.concatenate(\n",
        "        [ct.transformers_[0][2], ct.transformers_[1][1].get_feature_names()], axis=0\n",
        "    ),\n",
        ")\n",
        "\n",
        "X_train_preprocessed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "gZDz9DSfF3EV"
      },
      "source": [
        "---\n",
        "\n",
        "## √Årboles de Decisi√≥n\n",
        "\n",
        "√Årboles que fragmentan el dataset en condiciones.\n",
        "\n",
        "- Nodo ra√≠z: Sin arcos entrantes, 2 o m√°s salientes. Contienen una condici√≥n sobre alguna feature.\n",
        "- Nodo interno: 1 arco entrante, 2 o m√°s salientes.  Contienen una condici√≥n sobre alguna feature.\n",
        "- Nodo hoja/terminal: 1 arco entrante, nunguno saliente. Indican la clase.\n",
        "\n",
        "\n",
        "Nota: `tree` de `Scikit-learn` solo implementa 2 ramas salientes en los nodos ra√≠z y interno.\n",
        "\n",
        "Se entrenan recursivamente:\n",
        "\n",
        "Estrategia: Top down (greedy) - Divide y vencer√°s:\n",
        "\n",
        "---\n",
        "    Seleccionar un atributo para el nodo ra√≠z y crear rama para cada valor posible del atributo.\n",
        "    Luego: dividir las instancias del dataset en subconjuntos, uno para cada rama que se extiende desde el nodo.\n",
        "    Por √∫ltimo: repetir de forma recursiva para cada rama, utilizando s√≥lo las instancias que llegan a √©sta.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:12.133332Z",
          "start_time": "2020-09-11T17:43:12.121364Z"
        },
        "id": "xvtfekg2F3EV"
      },
      "outputs": [],
      "source": [
        "import graphviz\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "tree_pipe = Pipeline(\n",
        "    [(\"preprocesamiento\", ct), (\"tree\", DecisionTreeClassifier(criterion=\"entropy\"))]\n",
        ")\n",
        "\n",
        "# noten que aqu√≠ se pasa X_train ya que la etapa de\n",
        "# preprocesamiento est√° incluida en el pipeline (primera etapa)\n",
        "\n",
        "tree_pipe = tree_pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:12.153278Z",
          "start_time": "2020-09-11T17:43:12.135327Z"
        },
        "id": "cGIlq9i6F3EV"
      },
      "outputs": [],
      "source": [
        "y_pred = tree_pipe.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2KUsQkOF3EW"
      },
      "source": [
        "### Evaluaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNaUe2X8F3EW"
      },
      "outputs": [],
      "source": [
        "print(\"Matriz de confusi√≥n\\n\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOOUxRGyF3EW"
      },
      "source": [
        "### Visualizar el √°rbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSbivGeYF3EW"
      },
      "outputs": [],
      "source": [
        "# con esto obtenemos los nombres de las columnas\n",
        "# en el primer elemento del arreglo de obtienen las num√©ricas a partir\n",
        "# de la lista de la primera transformaci√≥n y en la segunda se obtienen a partir\n",
        "# de las columnas generadas por el one hot encoding.\n",
        "cols_names = np.concatenate(\n",
        "    [\n",
        "        tree_pipe.steps[0][1].transformers_[0][2],\n",
        "        tree_pipe.steps[0][1].transformers_[1][1].get_feature_names(),\n",
        "    ]\n",
        ")\n",
        "cols_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLbZVnRtF3EW"
      },
      "source": [
        "Para ejecutar la siguiente celda necesitar√°n tener instalado Graphviz:\n",
        "\n",
        "https://graphviz.org/download/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-11T17:43:12.239049Z",
          "start_time": "2020-09-11T17:43:12.156271Z"
        },
        "id": "NA3bww2xF3EW"
      },
      "outputs": [],
      "source": [
        "dot_data = export_graphviz(\n",
        "    tree_pipe.steps[1][1],\n",
        "    out_file=None,\n",
        "    feature_names=cols_names,\n",
        "    class_names=labels.unique(),\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True,\n",
        ")\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4q6FQnF3EW"
      },
      "source": [
        "> **Pregunta ‚ùì**: ¬øC√≥mo eligo los atributos y sus divisiones? \n",
        "\n",
        "- La idea es ir dividiendo el dataset en nodos a la vez que se crea el √°rbol m√°s peque√±o posible.\n",
        "- Heur√≠stica: escoge el atributo cuya divisi√≥n que produce nodos lo m√°s ‚Äúpuros‚Äù posibles (es decir, que pertenezcan mayoritariamente a la misma clase). El criterio comunmente utilizado es Information Gain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI6l4hclF3EW"
      },
      "source": [
        "### Resumen √Årboles de decisi√≥n\n",
        "\n",
        "\n",
        "\n",
        "| Ventajas                                | Deseventajas                                                                   |\n",
        "|-----------------------------------------|--------------------------------------------------------------------------------|\n",
        "| Simple de entender y interpretar.       | Se deben preprocesar las variables categ√≥ricas y ordinales antes de ser usadas |\n",
        "| Pueden ser visualizados.                | No escala tan bien a muchas decisiones (crece mucho el √°rbol)                  |\n",
        "| Al ser √°rbol, es muy r√°pido de evaluar. |                                                                                |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTE1sPTYF3EW"
      },
      "source": [
        "## Extra: Gu√≠a de Scikit-learn para Elegir el Modelo\n",
        "\n",
        "<img src='https://i.ibb.co/1XkHvRC/ml-map.png' />"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yg6KuykhF3ET",
        "q1oA0tVSF3ET",
        "FRNAspneF3EW"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}