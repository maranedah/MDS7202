{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b712acb-35c9-4137-a42d-f0e82e649b1d",
   "metadata": {},
   "source": [
    "# Clase 23: Redes Neuronales 2\n",
    "\n",
    "**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n",
    "\n",
    "**Profesor: Mauricio Araneda**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531ee05-818d-45da-990e-03f1fd9d2def",
   "metadata": {},
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Las redes neuronales pueden ser descritas como un modelo matemático de procesamiento de información compuesto por muchas funciones anidadas. Estas funciones están definidas por sus parámetros $w$.\n",
    "\n",
    "En general, una red neuronal puede considerarse como un sistema con las siguientes características:\n",
    "\n",
    "1. El procesamiento de la información ocurre en unidades llamadas neuronas.\n",
    "\n",
    "$$\n",
    "y=f\\left(\\sum_{i} x_{i} w_{i}+b\\right)\n",
    "$$\n",
    "\n",
    "<div align='center'>\n",
    "<img src='./resources/neuron.png' width=600/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "   Fuente: <a href='https://www.researchgate.net/figure/The-structure-of-the-artificial-neuron_fig2_328733599\n",
    " '> https://www.researchgate.net/figure/The-structure-of-the-artificial-neuron_fig2_328733599\n",
    "</a>\n",
    "</div>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097cab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# functions\n",
    "sign = lambda x: 1 if x > 0 else 0\n",
    "tanh = np.tanh\n",
    "sigmoid = lambda x: 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a691408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interior de la funcion: -1.0999999999999996\n",
      "Resultado: 0\n",
      "Clase correcta:  1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([14, 0.8, 37, 4, 8])\n",
    "label = 1\n",
    "\n",
    "w = np.array([1.1, -8, -0.5, -0.8, 1.2]) # <-- TODA la magia del Deep Learning es mover estos valores de w !!!!\n",
    "b = 2\n",
    "\n",
    "xw = x*w\n",
    "sum_xw = xw.sum() #Tambien llamado \"estado interno de la neurona\"\n",
    "\n",
    "f = sign #Funcion de activacion\n",
    "\n",
    "\n",
    "print(\"Interior de la funcion:\", sum_xw + b)\n",
    "print(\"Resultado:\", f(sum_xw + b))\n",
    "print(\"Clase correcta: \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4ee6b",
   "metadata": {},
   "source": [
    "\n",
    "Acá se hace el calculó $w x + b = \\sum_i x_i w_i + b$ sobre los inputs $x_i$ y los pesos $w_i$. Estos últimos, son valores numéricos que representan las conexiones entre neuronas, el peso $b$ se denomina *bias*. Luego, la salida es el resultado de aplicar la función de activación $f(\\cdot)$ sobre $w x + b$.\n",
    "\n",
    "\n",
    "2. Las neuronas están conectadas e intercambian información (o señales) por medio de sus conexiones.\n",
    "3. Las conexiones entre neuronas pueden tener mas o menos influencia en el resultado dependiendo de los pesos de estas.\n",
    "4. Cada neurona tiene un estado interno determinado por todas las conexiones que llegan a ella.\n",
    "5. Cada neurona tiene una función de activación que opera sobre su estado, esta función determina la información que se comparte a otras neuronas.\n",
    "\n",
    "<div align='center'>\n",
    "<img src='./resources/nn.png' width=600/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "   Fuente: <a href='https://www.researchgate.net/figure/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o_fig1_321259051 '> https://www.researchgate.net/figure/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o_fig1_321259051</a>\n",
    "</div>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf64ca5-8a18-4f12-8db0-6faf548ce682",
   "metadata": {},
   "source": [
    "## Funciones de activación\n",
    "---\n",
    "\n",
    "<div align='center'>\n",
    "<img src='./resources/activation_fn.png' width=600/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "   Fuente: <a href='https://www.researchgate.net/figure/Various-forms-of-non-linear-activation-functions-Figure-adopted-from-Caffe-Tutorial_fig3_315667264'> https://www.researchgate.net/figure/Various-forms-of-non-linear-activation-functions-Figure-adopted-from-Caffe-Tutorial_fig3_315667264</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1cd382-45e9-4b72-9364-2f98547467cc",
   "metadata": {},
   "source": [
    "## Arquitecturas\n",
    "---\n",
    "Segun como se distribuyan las conexiones entre neuronas se definen distintas **arquitecturas**.\n",
    "\n",
    "El tipo de arquitectura depende principalmente del tipo de problema que se quiera resolver:\n",
    "- Clasificacion -> Redes Neuronales Feed Forward\n",
    "- Imagenes -> Redes Convolucionales\n",
    "- Texto -> Redes Recurrentes\n",
    "\n",
    "<div align='center'>\n",
    "<img src='./resources/nn_zoo.png'/>\n",
    "</div>\n",
    "\n",
    "<div align='center'>\n",
    "   Fuente: <a href='https://www.asimovinstitute.org/neural-network-zoo/'> https://www.asimovinstitute.org/neural-network-zoo/</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e08e12-dccf-472a-a23c-bb82e657d4f6",
   "metadata": {},
   "source": [
    "## Aprendizaje\n",
    "---\n",
    "- Un proceso de **aprendizaje** asociado, que describe el proceso en el que la red aprende a resolver mejor la tarea entregada. La idea general es simple: \n",
    "\n",
    "\n",
    "  1. **Forward Propagation**: Predecir los ejemplos de entrenamiento (o forward).\n",
    "  2. **Backward Propagation**: Calcular un error y ajustar los parámetros de la red de forma proporcional al su valor sobre todos los pesos de la red (o backward). Tal como el caso del perceptrón, optimizamos estos valores usando descenso del gradiente pero de forma generalizada en cada capa. La idea es que se calculan los gradientes y luego se actualizan los pesos de cada unidad.\n",
    "  \n",
    "  Según wikipedia: \n",
    "  > Las salidas de error se propagan hacia atrás, partiendo de la capa de salida, hacia todas las neuronas de la capa oculta que contribuyen directamente a la salida. Sin embargo las neuronas de la capa oculta solo reciben una fracción de la señal total del error, basándose aproximadamente en la contribución relativa que haya aportado cada neurona a la salida original. Este proceso se repite, capa por capa, hasta que todas las neuronas de la red hayan recibido una señal de error que describa su contribución relativa al error total. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305414b5-0ecd-47f1-9687-514b4eb8bdc8",
   "metadata": {},
   "source": [
    "### Aprendizaje en `Pytorch`\n",
    "\n",
    "En `Pytorch` es posible implementar reglas de actualización basadas en propagación hacia atrás de manera automática. Para ello, es necesario comprender los tipos de datos asociados a esta librería. \n",
    "\n",
    "En primer lugar, se tienen los **tensores**, estos son arreglos n dimensionales, soportan almacenamiento en GPU. Las operaciones y sintaxis de este tipo de objetos es muy similar a los arreglos de NumPy. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Pytorch se mimetiza con NumPy en cuanto a la definición de sus métodos y compatibilidad cruzada, por ejemplo, para definir un arreglo de 2x2 se puede utilizar la función `randn` (análoga a la de NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70243f5f-6bd1-4582-8516-f2a2bd949e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mauri\\miniconda3\\envs\\c1do1\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3181,  0.3377],\n",
       "        [ 0.8672, -0.4030]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = torch.randn(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0bf529d-2217-4a5f-bc6d-0b99357e497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32055116,  0.74355652],\n",
       "       [ 1.03926835, -0.15982263]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24cf0b-4bb3-4d40-894a-119ca504cf25",
   "metadata": {},
   "source": [
    "Se pueden importar arreglos de numpy de manera bastante sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d03681-6006-4038-b3ed-42a8c8fd281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4359, -1.2461],\n",
       "        [-0.2001,  0.3537]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(2, 2)\n",
    "x = torch.from_numpy(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b06555-f844-4ddf-a4fb-e2f20dacc14e",
   "metadata": {},
   "source": [
    "### Uso de GPU\n",
    "---\n",
    "\n",
    "La función `torch.cuda.is_available()` permite detectar si existe una GPU disponble para computo. En caso afirmativo, se pueden cargar tensores en la GPU para su posterior computo, para ello, se utiliza la función `torch.device()` y el método `.to()` de los objetos `Tensor`.\n",
    "\n",
    "**Ejemplo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1f2e80-a13b-4e66-9539-f48b96dc1eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce48d4e-3df5-48eb-bd81-5c0257abfa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty((2, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79611f9b-ffb7-43a4-89e6-ad690c500d27",
   "metadata": {},
   "source": [
    "se modifica `x` de manera inplace en la CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cbec916-6614-4dde-8823-97fa1ae54635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add_(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3f2f7-07b7-450f-98ec-d19aa276d389",
   "metadata": {},
   "source": [
    "Se define un flujo en la CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb34cef3-26ae-4b74-9ecc-867a2bd611b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z en GPU: \n",
      " tensor([[2., 2.],\n",
      "        [2., 2.]], device='cuda:0')\n",
      "z en CPU:\n",
      " tensor([[2., 2.],\n",
      "        [2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Se detecta la presencia de una GPU\n",
    "if torch.cuda.is_available():\n",
    "    # Se obtiene un objeto que apunta a la GPU descubierta\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    # en el caso contrario,\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Se crea un tensor y se carga en el dispositivo especificado en device\n",
    "y = torch.ones_like(x, device=device)  #\n",
    "\n",
    "# Se envia un vector a la GPU luego de ser definido\n",
    "x = x.to(device)\n",
    "\n",
    "# Se obtiene un resultado en la GPU y se transfiere a la CPU\n",
    "z = x + y\n",
    "print(\"z en GPU: \\n\", z)\n",
    "print(\"z en CPU:\\n\", z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879518a1-a62f-4164-9b44-532909a7658f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58072d32-a868-4c58-beda-d49e56716a12",
   "metadata": {},
   "source": [
    "### Autograd \n",
    "---\n",
    "El motor central en las redes neuronales de PyTorch es la librería  `autograd`. Esta entrega herramientas de diferenciacion automatica para todas las operaciones hechas sobre objetos tipo `Tensor`. \n",
    "\n",
    "\n",
    "Como se estudio anteriormente, los tensores son objetos similares a los arreglos de NumPy en cuanto a sus métodos y manejo. Aparte de permitir el computo en GPU, poseen el atributo booleano `.requires_grad`. Si para un tensor, tal atributo tiene el valor `True`, se comienzan a registrar todas operaciones aplicadas aplicadas sobre este. Tal registro se lleva a cabo de manera a automática, generando una estructura jeraquica codificada en un grafo denotado como **DCG** (grafo dinámico computacional). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f9eb35-492f-426e-8ec8-d186e624715a",
   "metadata": {},
   "source": [
    "### Grafo Dinámico Computacional (DCG)\n",
    "\n",
    "Un **DCG** grafo es grafo acíclico y dirigido, sus hojas son los tensores de **input** y las raíces son los tensores de respuesta luego de la última operación **output**. \n",
    "\n",
    "Estan diseñados para **actualizar los valores de w de forma automatica**. Como lo hace? El grafo dinamico permite detectar que funciones generaron el estado interno de cada neurona. Si sabemos que funciones lo generaron, podemos derivar estas funciones para saber si influencia en los resultados y movernos de acuerdo a estos patrones.\n",
    "\n",
    "En resumen: el grafo permite calcular gradientes para cada parámetro.\n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "<img src='./resources/grafo_comp.png' width=600/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Cada tensor del cual se lleva un registro, tiene el atributo `.grad_fn` que referencia al objeto de clase `Function` que dio origen a tal tensor. En el caso de tensores creados \"a mano\", `.grad_fn`será `None` a menos que especifiquemos lo contrario. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fac441-ab21-43cc-bbcc-1b18203cdfba",
   "metadata": {},
   "source": [
    "**Ejemplo**\n",
    "\n",
    "Creamos dos tensores con algunos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e51af4-2a70-483d-b7b5-18b373704025",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "b = torch.tensor([6.0, 4.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0b71ca8-733a-48cf-b076-c307ee2142b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b1fa94-93d6-4dcb-8fa6-142185afb602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 4.], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c2ef7-bb4f-4f62-bf16-be008cd493fe",
   "metadata": {},
   "source": [
    "Y luego los operamos según:\n",
    "$$Q = 3a ^3 - b ^ 2$$    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3bb52b-cfc4-4773-9752-e96a9d49fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3 * a ** 3 - b ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e387e5df-0fb0-4bee-aa5a-094b6e7f1902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb101410-abbe-42e0-9605-aecdb5f76294",
   "metadata": {},
   "source": [
    "Los gradientes de esta operación serán:\n",
    "    \n",
    "$$\\frac{\\partial Q}{a} = 9a ^ 2$$\n",
    "y \n",
    "$$\\frac{\\partial Q}{b} = -2b$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a00455d-c8be-4cc4-bc96-32015c2e6c8d",
   "metadata": {},
   "source": [
    "Por lo tanto, el grafo generado será: \n",
    "    \n",
    "<div align='center'>\n",
    "<img src='./resources/ej_1.png' width=600/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f5e42-02d7-436a-a69f-5ac4874c4950",
   "metadata": {},
   "source": [
    "Al llamar a `Q.backward()`, `autograd` calcula automáticamente los gradientes para `a` y `b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2b8607-a1d4-481f-8400-21433ce18a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1.0, 1.0])\n",
    "\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf56a98-e543-4191-baf9-3e38734e805b",
   "metadata": {},
   "source": [
    "Como el resultado tiene dos elementos, las derivadas parciales serán calculadas en cada dimensión.\n",
    "\n",
    "Noten que en el caso anterior entregamos un gradiente externo a través de `external_grad`. Esto es en la práctica, entregarle los valores iniciales a `backward()` para que luego los propague. Fijense que la derivada parcial de Q respecto a si mismo es: \n",
    "\n",
    "\n",
    "$$\\frac{\\partial Q}{\\partial Q} = 1$$\n",
    "\n",
    "\n",
    "Luego, al ser evaluados, los valores serán: \n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "<img src='./resources/ej_2.png' width=600/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6cda080-f849-4447-8440-780c67a9802a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fa3bb8c-a50b-4d8c-b54c-bc15c3de5bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 81.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "209ce5c4-6d25-411e-bb85-72de3938835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  -8.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111edf22-d249-4a04-bdc2-1d176ee43e03",
   "metadata": {},
   "source": [
    "> **Nota:** Para hacer operaciones sin registrar gradientes se utiliza el context manager `torch.no_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80254d50-70a9-4c8e-9282-f7a4fb693636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se requiere gradiente en y: True\n",
      "Se requiere gradiente en y (context manager):  False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(25.0, requires_grad=True)\n",
    "y = x * 2\n",
    "\n",
    "print(\"Se requiere gradiente en y:\", y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    print(\"Se requiere gradiente en y (context manager): \", y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb54f9-87a9-45f1-a144-c8c81dfefea9",
   "metadata": {},
   "source": [
    "## Aprendizaje Profundo\n",
    "\n",
    "El aprendizaje profundo o *deep learning* consiste en la aplicación de modelos basados en redes neuronales con múltiples capas ocultas. Este tipo de redes presenta la ventaja pues sus estructuras no solo permiten predecir el output de un modelo, sino que también aprender característcas en los datos, es decir, generar representaciones abstractas de los datos de entrada. \n",
    "\n",
    "En la práctica, los algoritmos de aprendizaje profundo son redes neuronales consistentes de neuronas y capas. Para diferenciarlos, es necesario observar la arquitectura y sus procesos de aprendizaje. Acá podemos distinguir a grandes rasgos las redes MLP o feedforward, convolucionales, Recurrentes y autoencoders. \n",
    "\n",
    "Antes de pasar a estudiar dichas arquitecturas, se discutirán algunos aspectos referentes al proceso de aprendizaje que en este tipo de algoritmos se relaciona estrechamente con los métodos de optimización a utilizar. \n",
    "\n",
    "Ya se aplicó el algoritmo de **descenso de gradiente estocástico SGD** en combinación con backpropagation. Este algoritmo puede ser modificado al introducir **momentum**. El algorimto SGD se puede resumir de la siguiente manera:\n",
    "\n",
    "* Se sigue la dinámica de actualización $w \\rightarrow w-\\lambda \\nabla(J(w))$, donde $\\lambda$ se denota como *learning rate*. \n",
    "\n",
    "* Para añadir momentum, se puede añadir un *peso de actualización* de la forma:\n",
    "$$\n",
    "\\triangle w \\rightarrow \\mu \\cdot \\triangle w-\\lambda(\\nabla J(w))\n",
    "$$\n",
    "\n",
    "Donde $\\triangle w$ representa el vector de actualización añadido a $w$ en la iteración anterior, $\\mu$ es un parámetro que determina la dependencia de nuevos valores para $w$ en función valores anteriores. $\\mu \\cdot \\triangle w$ se denota como *momentum*. \n",
    "\n",
    "* Finalmente se crea una nueva regla de actualización mediante:\n",
    "$$\n",
    "w \\rightarrow w+\\Delta w\n",
    "$$\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "1. ¿Qué ventajas puede proporcionar añadir la componente de momentum?\n",
    "\n",
    "2. Otro algoritmo útil es **Adam**, investigue sobre su funcionamiento y ventajas. [link](https://arxiv.org/abs/1412.6980)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f21370-c6c9-48f8-8b29-de72ffbd72cf",
   "metadata": {},
   "source": [
    "### Redes Neuronales Convolucionales\n",
    "\n",
    "Las redes neuronales convolucionales CNN (por sus siglas en ingles) fueron para resolver problemas de *visión computacional*. Aquí se busca obtener conocimiento por medio del manejo de representaciones interpretables de manera óptica por humanos (imagenes y videos por ejemplo). Tal proceso de obtención de información posee características bastante especificas y difíciles de codificar en una máquina. P\n",
    "\n",
    "Por ejemplo, en el contexto de imagenes, se puede asumir que píxeles cercanos (bajo cierta métrica) se relacionan de mejor manera y que por tanto su aglomeración tiene sentido, por otra parte, el significado de una imagen puede depender fuertemente del contexto de ciertas estructuras o patrones abstractos difíciles de programar en un software. \n",
    "\n",
    "Una red neuronal múlticapa, en su forma más sencilla, considera a los datos de entrada como arreglos y a priori no saca provecho de la estructura de su input. En el ejemplo de las imagenes, tal red no puede distinguir vecinos posicionales (píxeles cercanos) pues recibe como input un arreglo unidimensional. En este contexto, nacen las CNN's, estas permiten sacar provecho de la estructura (especialmente en imágenes) haciendo posible mejorar la interacción entre neuronas cercanas. En problemas visuales, esto consiste en hacer que las neuronas procesen información originada en píxeles cercanos entre si, para lograr esto se hace uso de **capas convolucionales**.\n",
    "\n",
    "Una capa convolucional consiste de un conjunto de filtros o *kernels*. Estos a la vez, consisten en un conjunto de pesos (a aprender), cada kernel es aplicado en *areas* de los datos de entrada. En la siguiente animación ([fuente](https://m-alcu.github.io/)) se puede observar un kernel de 3x3x3 aplicado sobre una imagen de 9x9x3, en ambos casos, el último índice es 3 y corresponde a la cantidad de canales de color asociados a la imagen procesada.\n",
    "\n",
    "<div align='center'>\n",
    "<img src='https://m-alcu.github.io/assets/cntk103d_conv2d_final.gif' width=600/>\n",
    "</div>\n",
    "\n",
    "Si la imagen es la capa input de la red, la acción del kernel consiste en asociar cada dato de entrada con un peso, en el ejemplo de la animación, el kernel aplicado posee 3x3x3 pesos que se *comparten* en cada región procesada de la imagen. El output de esta aplicación es una suma ponderada entre los píxeles de entrada y los pesos del filtro. Al recorrer toda la imagen, se tiene un nuevo conjunto de inputs sobre los cuales es posible operar con una función de activación u otra capa de neuronas (convolcional o simplemente lineal-conectada).\n",
    "\n",
    "La idea intuitiva del kernel es de extraer alguna caracteística especifica de la imagen input (contornos, agrupaciones de colores, formas, etc...).  Gracias a que los pesos del kernel se mantienen mientras recorre la imagen, se logra una reducción en la cantidad de parámetros necesarios para entrenar una capa de la red. En algunas oportunidades, los kernels entrenados (conjuntos de pesos optimizados según alguna función de pérdida) pueden ser interpretables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "270fe3a6-561e-48cc-988b-9259b694c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78054a12-ccad-423d-9d39-d773a4da460e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18350454-8562-48f9-aa79-46c8793e73a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### `Datasets` en `Pytorch`\n",
    "\n",
    "Pytorch no solo facilita la creación de redes neuronales. También provee varias utilidades y datasets conocidos en interfaces muy sencillas de usar. Tal es el caso de los `Datasets`.\n",
    "\n",
    "Los `datasets` son clases que manejan de forma eficiente y proveen un interfaz estandar para los conjuntos de datos y sus respectivas etiquetas en  `pytorch`. Tanto audio, como texto y video cuentan con ellos. La documentación asociada se encuenta en el siguiente link: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "Existen dos formas de crear un `dataset`:\n",
    "\n",
    "1. Cargar un dataset predefinido.\n",
    "2. Crear un dataset personalizado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8605596-f3d7-4d11-97eb-72a5acda0780",
   "metadata": {},
   "source": [
    "#### Fashion MNIST\n",
    "\n",
    "En esta ocación, crearemos una red neuronal convolucional para resolver el problema del dataset `Fashion MNIST` (https://research.zalando.com/project/fashion_mnist/fashion_mnist/). \n",
    "\n",
    "\n",
    "> Fashion-MNIST is a dataset of Zalando’s article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Fashion-MNIST is intended to serve as a direct drop-in replacement of the original MNIST dataset for benchmarking machine learning algorithms. \n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "<img src='./resources/fashion_mnist.png'    />\n",
    "</div>\n",
    "\n",
    "El ejercicio estará basado en https://www.kaggle.com/pankajj/fashion-mnist-with-pytorch-93-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73cbdff-fc8d-4f9d-af72-43884dbed0ce",
   "metadata": {},
   "source": [
    "En el siguiente link pueden encontrar todos los datasets de imágenes disponibles en `pytorch`: https://pytorch.org/vision/stable/datasets.html\n",
    "\n",
    "<center>\n",
    "<img src='./resources/fashion_mnist_dataset.png' width=600/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d71cacd-e7cc-4fdc-bbfb-321593e652de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", download=True, transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06adbcb4-9e36-4da6-a0cb-a2d55c4d2024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "838491ca-c7cf-4ccb-94b8-c16527ad8ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f1635b9-6c02-458f-99b1-c3cb9a0b743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "\n",
    "def output_label(label):\n",
    "    input = label.item() if type(label) == torch.Tensor else label\n",
    "    return labels_map[input]\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed07a10-0e2f-4099-b04c-14f514c075bf",
   "metadata": {},
   "source": [
    "#### `Dataloaders` para iterar sobre el `Dataset`\n",
    "\n",
    "Usar Stochastic gradient descent (SGD) (i.e., entenar de 1 a 1 usando ejemplos aleatorios) permite encontrar óptimos locales relativamente buenos, ¡pero es muy lento!.\n",
    "\n",
    "Una forma de solucionar esto es usar mini-batches, es decir, un grupo de ejemplos seleccionados aleatoriamente. Para este fin, `pytorch` provee de `DataLoaders`, las cuales son clases que nos permiten generar mini-batches de forma muy sencilla.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "353fbdff-01cd-4765-8831-ebe782c6be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "009e40c1-0493-47f9-84c4-85b060bb5c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([100, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Bag\n"
     ]
    }
   ],
   "source": [
    "# Por ejemplo, para mostrar una imagen en particular:\n",
    "\n",
    "# obtenemos el batch\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "# obtenemos el primer elemento\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {output_label(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef191e0b-d86f-4eb6-b460-49ec29babb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reiniciamos por si acaso...\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2def5-1710-4865-9dac-75e28f8cadab",
   "metadata": {},
   "source": [
    "#### La red\n",
    "\n",
    "En este caso, vamos a implementar nuestra red como una clase. Para que `pytorch` la reconozca como tal, esta debe extender la clase `nn.Module`.\n",
    "\n",
    "La red estará compuesta por las siguientes capas:\n",
    "\n",
    "1. 1 capa secuencial compuestas por:\n",
    "   - Una convoluciónde $3x3$ con padding 1 y salto (stride) de 1.\n",
    "   - Normalización de Batch.\n",
    "   - Función de Activación ReLU.\n",
    "   - Max Pooling de 2*2 y salto (stride) 2.\n",
    "\n",
    "2. 1 capa secuencial compuestas por:\n",
    "   - Una convoluciónde $3x3$ con padding 0 y salto (stride) de 1.\n",
    "   - Normalización de Batch.\n",
    "   - Función de Activación ReLU.\n",
    "   - Max Pooling de 2*2 y salto (stride) 2.\n",
    "   \n",
    "3. Aplanamiento de la salida convolucional.\n",
    "\n",
    "4. 3 Capas fully-connected.La última tiene salida de tamaño 10 con Dropout.\n",
    "\n",
    "\n",
    "Más información acerca de padding, stride y max-pooling: https://speakerdeck.com/mloey/convolutional-neural-network-models?slide=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fca492a-fe0f-4f33-8e2e-3f3e2e4a3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=64 * 6 * 6, out_features=600)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.fc3(out)\n",
    "        # noten que al optimizar con CrossEntropyLoss no necesitamos que la salida sea probabilidad.\n",
    "        # es decir, no necesitamos poner un softmax previo a la salida\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffb9b016-2328-4c92-a32a-556395f188d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
      "  (relu_1): ReLU()\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
      "  (relu_2): ReLU()\n",
      "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48314337-a1b5-44d7-9dff-d3cdda10023d",
   "metadata": {},
   "source": [
    "\n",
    "Making a model of our CNN class\n",
    "\n",
    "    Creating a object(model in the code)\n",
    "    Transfering it into GPU if available.\n",
    "    Defining a Loss function. we're using CrossEntropyLoss() here.\n",
    "    Using Adam algorithm for optimization purpose.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b7baadd-2d1f-4509-a29f-ad7455f46f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.32347896695137024, Accuracy: 87.87999725341797%\n",
      "Iteration: 1000, Loss: 0.18642112612724304, Accuracy: 89.3499984741211%\n",
      "Iteration: 1500, Loss: 0.13182774186134338, Accuracy: 90.8699951171875%\n",
      "Iteration: 2000, Loss: 0.23782339692115784, Accuracy: 90.50999450683594%\n",
      "Iteration: 2500, Loss: 0.11306600272655487, Accuracy: 91.25%\n",
      "Iteration: 3000, Loss: 0.2028452754020691, Accuracy: 91.29000091552734%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "# Lists for visualization of loss and accuracy\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Lists for knowing classwise accuracy\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Transfering images and labels to GPU if available\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(train)\n",
    "        loss = error(outputs, labels)\n",
    "\n",
    "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Propagating the error backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizing the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        # Testing the model\n",
    "\n",
    "        if not (count % 50):  # It's same as \"if count % 50 == 0\"\n",
    "            total = 0\n",
    "            correct = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "\n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "\n",
    "                outputs = model(test)\n",
    "\n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "\n",
    "                total += len(labels)\n",
    "\n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        if not (count % 500):\n",
    "            print(\n",
    "                \"Iteration: {}, Loss: {}, Accuracy: {}%\".format(\n",
    "                    count, loss.data, accuracy\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "300a6a4e-7cce-4441-b3f3-694027f1c843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "predictions_l = [predictions_list[i].tolist() for i in range(len(predictions_list))]\n",
    "labels_l = [labels_list[i].tolist() for i in range(len(labels_list))]\n",
    "predictions_l = list(chain.from_iterable(predictions_l))\n",
    "labels_l = list(chain.from_iterable(labels_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bae3226a-409b-4674-924a-f0c889f0b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for CNN :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84     60000\n",
      "           1       0.99      0.98      0.98     60000\n",
      "           2       0.83      0.85      0.84     60000\n",
      "           3       0.88      0.90      0.89     60000\n",
      "           4       0.83      0.81      0.82     60000\n",
      "           5       0.98      0.97      0.97     60000\n",
      "           6       0.71      0.68      0.70     60000\n",
      "           7       0.94      0.95      0.94     60000\n",
      "           8       0.98      0.97      0.97     60000\n",
      "           9       0.96      0.96      0.96     60000\n",
      "\n",
      "    accuracy                           0.89    600000\n",
      "   macro avg       0.89      0.89      0.89    600000\n",
      "weighted avg       0.89      0.89      0.89    600000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion_matrix(labels_l, predictions_l)\n",
    "print(\n",
    "    \"Classification report for CNN :\\n%s\\n\"\n",
    "    % (classification_report(labels_l, predictions_l))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aefe33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea7473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7036fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7b604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
